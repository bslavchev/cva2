{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\Bobby\\.conda\\envs\\dl\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GaussianNoise\n",
    "from keras.utils import to_categorical\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Data corresponds to an emotion tag, a 48x48 greyscale picture flattened, and a tag indicating if the image belongs to the test set or the training set.\n",
    "df = pd.read_csv('./data/fer2013.csv')\n",
    "\n",
    "train = df[df['Usage']=='Training']\n",
    "test = df[df['Usage']=='PublicTest']\n",
    "\n",
    "#TODO: We might want to augment data with ImageDataGenerator \n",
    "\n",
    "#TODO: We might want to do some image pre-processing\n",
    "\n",
    "\n",
    "#Splits data in training and testing, as well as formatting data to right input and output shapes\n",
    "\n",
    "X_train = np.array(train.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48,1).astype('float32')))\n",
    "X_test = np.array(test.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48,1).astype('float32')))\n",
    "\n",
    "#Turn the array of 3D arrays into a 4D array\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "y_train = to_categorical(train['emotion'])\n",
    "y_test =  to_categorical(test['emotion'])\n",
    "\n",
    "#X_train = X_train / 255\n",
    "#X_test = X_test / 255\n",
    "\n",
    "#Splits off a validation set\n",
    "X_val = X_train[-4000:]\n",
    "y_val = y_train[-4000:]\n",
    "X_train = X_train[:-4000]\n",
    "y_train = y_train[:-4000]\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        #rotation_range=40,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        #brightness_range=0.2,\n",
    "        #zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n",
    "        #zca_whitening: Boolean. Apply ZCA whitening.\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,    \n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#Define dimensions of input and output layers\n",
    "D_in = X_train[0].shape\n",
    "D_out = tuple(y_train[0].shape)\n",
    "print(D_in)\n",
    "print(D_out[0])\n",
    "\n",
    "#Sets up model. To Bobby: Can we make this smarter so you and I can do different models?\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(GaussianNoise(0.1, input_shape=(tuple(D_in))))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(tuple(D_in))))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.add(Dense(D_out[0], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#TODO: Train networks, evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 107,015\n",
      "Trainable params: 107,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/500\n",
      "386/386 [==============================] - 27s 69ms/step - loss: 1.2421 - accuracy: 0.5302 - val_loss: 108.1487 - val_accuracy: 0.3620\n",
      "Epoch 2/500\n",
      "386/386 [==============================] - 27s 69ms/step - loss: 1.2280 - accuracy: 0.5339 - val_loss: 105.6871 - val_accuracy: 0.3857\n",
      "Epoch 3/500\n",
      "386/386 [==============================] - 26s 67ms/step - loss: 1.2181 - accuracy: 0.5399 - val_loss: 102.1234 - val_accuracy: 0.3870\n",
      "Epoch 4/500\n",
      "386/386 [==============================] - 26s 69ms/step - loss: 1.2017 - accuracy: 0.5442 - val_loss: 105.3555 - val_accuracy: 0.3968\n",
      "Epoch 5/500\n",
      "386/386 [==============================] - 27s 71ms/step - loss: 1.1970 - accuracy: 0.5516 - val_loss: 74.5438 - val_accuracy: 0.4347\n",
      "Epoch 6/500\n",
      "386/386 [==============================] - 27s 70ms/step - loss: 1.1806 - accuracy: 0.5540 - val_loss: 94.0540 - val_accuracy: 0.3935\n",
      "Epoch 7/500\n",
      "386/386 [==============================] - 27s 71ms/step - loss: 1.1757 - accuracy: 0.5563 - val_loss: 93.2363 - val_accuracy: 0.3938\n",
      "Epoch 8/500\n",
      "386/386 [==============================] - 27s 70ms/step - loss: 1.1661 - accuracy: 0.5621 - val_loss: 97.8564 - val_accuracy: 0.3910\n",
      "Epoch 9/500\n",
      "386/386 [==============================] - 27s 70ms/step - loss: 1.1557 - accuracy: 0.5677 - val_loss: 107.2335 - val_accuracy: 0.3820\n",
      "Epoch 10/500\n",
      "386/386 [==============================] - 27s 71ms/step - loss: 1.1483 - accuracy: 0.5647 - val_loss: 114.7360 - val_accuracy: 0.3425\n",
      "Epoch 11/500\n",
      "386/386 [==============================] - 27s 70ms/step - loss: 1.1430 - accuracy: 0.5695 - val_loss: 105.3440 - val_accuracy: 0.3758\n",
      "Epoch 12/500\n",
      "386/386 [==============================] - 27s 69ms/step - loss: 1.1330 - accuracy: 0.5730 - val_loss: 108.4865 - val_accuracy: 0.3837\n",
      "Epoch 13/500\n",
      "386/386 [==============================] - 28s 73ms/step - loss: 1.1229 - accuracy: 0.5762 - val_loss: 84.8201 - val_accuracy: 0.4275\n",
      "Epoch 14/500\n",
      "386/386 [==============================] - 28s 71ms/step - loss: 1.1284 - accuracy: 0.5778 - val_loss: 84.6793 - val_accuracy: 0.4062\n",
      "Epoch 15/500\n",
      "386/386 [==============================] - 27s 71ms/step - loss: 1.1211 - accuracy: 0.5757 - val_loss: 108.8570 - val_accuracy: 0.3485\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_val, y_val), steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=500, callbacks = callbacks)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=500,\n",
    "#                     # We pass some validation for\n",
    "#                     # monitoring validation loss and metrics\n",
    "#                     # at the end of each epoch\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     callbacks = callbacks\n",
    "#                    )\n",
    "\n",
    "#print('\\nhistory dict:', history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fe47abeab539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dl] *",
   "language": "python",
   "name": "conda-env-.conda-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
